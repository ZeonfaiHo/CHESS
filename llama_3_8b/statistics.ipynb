{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = torch.load('datasets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./custom_llama_statistics/model')\n",
    "model = AutoModelForCausalLM.from_pretrained('./custom_llama_statistics/model', torch_dtype=torch.float32, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "device_2 = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size, block_size):\n",
    "    start_idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_level = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = 0.0\n",
    "n_batch = 64\n",
    "accum_steps = 4\n",
    "batch_size = 1\n",
    "block_size = 2048\n",
    "torch.manual_seed(42)\n",
    "\n",
    "gate_proj_states_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "up_proj_states_mean_squares = [torch.zeros(model.config.intermediate_size) for _ in range(len(model.model.layers))]\n",
    "attention_inputs_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "attention_outputs_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "\n",
    "gate_proj_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.intermediate_size]) for _ in range(len(model.model.layers))]\n",
    "up_proj_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.intermediate_size]) for _ in range(len(model.model.layers))]\n",
    "attention_input_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.hidden_size]) for _ in range(len(model.model.layers))]\n",
    "attention_output_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.hidden_size]) for _ in range(len(model.model.layers))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        for batch_idx in range(accum_steps):\n",
    "            inputs, labels = get_batch(datasets['train'], batch_size, block_size)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(len(model.model.layers)):\n",
    "                states = model.model.layers[layer_idx].mlp.gate_proj_states\n",
    "                gate_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                states = model.model.layers[layer_idx].mlp.up_proj_states\n",
    "                up_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                states = model.model.layers[layer_idx].self_attn.attention_input_states\n",
    "                attention_input_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                states = model.model.layers[layer_idx].self_attn.attention_output_states\n",
    "                attention_output_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "        \n",
    "        for layer_idx in range(len(model.model.layers)):   \n",
    "            gate_proj_states_thresholds[layer_idx] += gate_proj_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(gate_proj_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "            attention_inputs_thresholds[layer_idx] += attention_input_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(attention_input_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "            attention_outputs_thresholds[layer_idx] += attention_output_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(attention_output_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "            \n",
    "            up_proj_states_mean_squares[layer_idx] += (torch.sum(up_proj_states[layer_idx].to(device_2) ** 2, dim=0).to('cpu') / up_proj_states[layer_idx].size(0)).to('cpu')\n",
    "\n",
    "for layer_idx in range(len(model.model.layers)):\n",
    "    gate_proj_states_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    attention_inputs_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    attention_outputs_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    up_proj_states_mean_squares[layer_idx] /= n_batch // accum_steps\n",
    "\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "gate_proj_states_thresholds_2 = [torch.zeros(model.config.intermediate_size) for _ in range(len(model.model.layers))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        for batch_idx in range(accum_steps):\n",
    "            inputs, labels = get_batch(datasets['train'], batch_size, block_size)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(len(model.model.layers)):\n",
    "                states = model.model.layers[layer_idx].mlp.gate_proj_states\n",
    "                gate_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "        \n",
    "        for layer_idx in range(len(model.model.layers)):   \n",
    "            importance_scores = gate_proj_states[layer_idx] ** 2 * up_proj_states_mean_squares[layer_idx]\n",
    "            importance_thresholds[layer_idx] += importance_scores.to(device_2).flatten().kthvalue(int(importance_scores.numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "for layer_idx in range(len(model.model.layers)):\n",
    "    importance_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    gate_proj_states_thresholds_2[layer_idx] = (importance_thresholds[layer_idx].expand_as(gate_proj_states_thresholds_2[layer_idx]) / up_proj_states_mean_squares[layer_idx]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {'gate_proj_states_thresholds': gate_proj_states_thresholds, 'attention_inputs_thresholds': attention_inputs_thresholds, 'attention_outputs_thresholds': attention_outputs_thresholds, 'gate_proj_states_thresholds_2': gate_proj_states_thresholds_2}\n",
    "\n",
    "torch.save(thresholds, 'thresholds_0_5.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
